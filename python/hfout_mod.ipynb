{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to read and prepare WRF high-frequency output files, generated via special streams (without explicit time information).\n",
    "\n",
    "- Fixes hfout output times\n",
    "- Writes out base state file needed for write_qvar_vint.py\n",
    "\n",
    "This script leverages the CDO (https://code.mpimet.mpg.de/projects/cdo/) module via subprocess (executes as a terminal command) to generate basic time series, which helps for checking for RCE. This should be available either by loading as a module or installing into the conda/mamba kernel you're running.\n",
    "\n",
    "James Ruppert  \n",
    "21 April 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from netCDF4 import Dataset\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "from matplotlib import ticker, colors, rc\n",
    "import matplotlib.pyplot as plt\n",
    "# from wrf import getvar, interplevel, disable_xarray, ALL_TIMES\n",
    "from wrf import interplevel\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from scipy import interpolate\n",
    "from read_wrf_ideal import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small domain model time specs\n",
    "npd_wrf = 48 # time steps per day\n",
    "npd_hf = 288 # time steps per day\n",
    "# npfile = npd # time steps per output file\n",
    "nd=50 # total n-days of run\n",
    "\n",
    "# Vertical interpolation settings\n",
    "dp_int = 20 # hPa\n",
    "top_p = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories and model output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m figdir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/glade/u/home/ruppert/figures/wrf-ideal/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# WRFOUT files\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m wrffiles, times \u001b[38;5;241m=\u001b[39m get_wrf_file_list(wrfdir, wrftag)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# times_wrf = get_times_wrffiles(wrffiles)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print('WRF file list contains',times_wrf.size,'time steps')\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# print('WRF file list contains',times_wrf.size/npd_wrf,'days')\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Horizontal dimensions\u001b[39;00m\n\u001b[1;32m     19\u001b[0m varfil_main \u001b[38;5;241m=\u001b[39m nc\u001b[38;5;241m.\u001b[39mDataset(wrffiles[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "test_process='ctl'\n",
    "# test_process='xcrf'\n",
    "\n",
    "# wrfdir = \"/glade/derecho/scratch/ruppert/wrf-ideal/largedom2/\"\n",
    "wrfdir = \"/glade/campaign/univ/uokl0049/ideal/largedom2/\"+test_process+\"/\"\n",
    "workdir = \"/glade/work/ruppert/wrf-ideal/\"\n",
    "wrftag = \"wrfout_d01\"\n",
    "hftag = \"hfout_d01\"\n",
    "\n",
    "figdir = \"/glade/u/home/ruppert/figures/wrf-ideal/\"\n",
    "\n",
    "# WRFOUT files\n",
    "wrffiles = get_wrf_file_list(wrfdir, wrftag)\n",
    "# times_wrf = get_times_wrffiles(wrffiles)\n",
    "# print('WRF file list contains',times_wrf.size,'time steps')\n",
    "# print('WRF file list contains',times_wrf.size/npd_wrf,'days')\n",
    "\n",
    "# Horizontal dimensions\n",
    "varfil_main = nc.Dataset(wrffiles[0])\n",
    "nx1 = varfil_main.dimensions['south_north'].size\n",
    "nx2 = varfil_main.dimensions['west_east'].size\n",
    "varfil_main.close()\n",
    "\n",
    "# High-frequency (HFOUT) files\n",
    "hffiles = get_wrf_file_list(wrfdir, hftag)\n",
    "# print('HF file list contains',times_hf.size-1,'time steps')\n",
    "# print('HF file list contains',(times_hf.size-1)/npd_hf,'days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix output time steps\n",
    "\n",
    "At model restarts, output from special streams begins at output_time_step + 1, yielding inconsistent files from then onward, e.g., starting from 00:05 UTC instead of 00:00 UTC.\n",
    "\n",
    "The problem is corrected simply: this code block creates a copy of the first time step of the pre-restart output file, with the original naming convention. The original file is first saved as *sav.hfout...*). The new file will then have a single time step but will be in the correct sequence for future *cdo mergetime* calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do_fix_output_times = True\n",
    "do_fix_output_times = False\n",
    "\n",
    "# Create string array of file-specific commands\n",
    "if do_fix_output_times:\n",
    "    # for ifil in range(len(hffiles)):\n",
    "    for ifil in range(23,24):\n",
    "        if hffiles[ifil][-4] == '5':\n",
    "            print(hffiles[ifil])\n",
    "            # First save a copy of the original, then \n",
    "            outfname = 'sav.'+hffiles[ifil-1].split('/')[-1]\n",
    "            outfile = wrfdir+outfname\n",
    "            process = subprocess.Popen(['mv '+hffiles[ifil-1]+' '+outfile], shell=True, stdout=subprocess.PIPE, universal_newlines=True)\n",
    "            lines = process.stdout.readlines()\n",
    "            for iline in lines:\n",
    "                print(iline)\n",
    "            print()\n",
    "            process = subprocess.Popen(['cdo copy -seltimestep,1 '+outfile+' '+hffiles[ifil-1]], shell=True, stdout=subprocess.PIPE, universal_newlines=True)\n",
    "            lines = process.stdout.readlines()\n",
    "            for iline in lines:\n",
    "                print(iline)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate base state files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do_cdo_basestate = True\n",
    "do_cdo_basestate = False\n",
    "\n",
    "basestate_file = \" \"+workdir+'python/largedom_base_state.nc'\n",
    "\n",
    "if do_cdo_basestate:\n",
    "\n",
    "    # Generate mean base state file for single time step (doesn't change)\n",
    "    # First remove file if exists\n",
    "    process = subprocess.Popen(['rm -f '+basestate_file], shell=True, stdout=subprocess.PIPE, universal_newlines=True)\n",
    "    # Generate file\n",
    "    process = subprocess.Popen(['cdo fldavg -selname,PHB,PB -seltimestep,1 '+wrffiles[0]+basestate_file], shell=True, stdout=subprocess.PIPE, universal_newlines=True)\n",
    "    lines = process.stdout.readlines()\n",
    "    for iline in lines:\n",
    "        print(iline)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
